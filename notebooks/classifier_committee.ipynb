{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prepare Environment",
   "id": "1b2b38c6f21d9e78"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-18T16:46:54.406283Z",
     "start_time": "2024-12-18T16:46:52.223812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset.dataset_info import ClassifierDatasetInfo, MMClassifierDatasetInfo\n",
    "from dataset.dataset_type import DatasetType\n",
    "from dataset.STARCOP_dataset import STARCOPDataset\n",
    "\n",
    "from files_handler import ModelFilesHandler\n",
    "\n",
    "os.chdir(r\"D:\\Projects\\studia\\polsl_ssi_1\\MethaneDetection\\Thesis\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "dataset = STARCOPDataset(\n",
    "    data_path=r\"data\",\n",
    "    data_type=DatasetType.TEST,\n",
    "    image_info_class=ClassifierDatasetInfo,\n",
    "    normalization=False\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=6, shuffle=False)\n",
    "\n",
    "mm_dataset = STARCOPDataset(\n",
    "    data_path=r\"data\",\n",
    "    data_type=DatasetType.TEST,\n",
    "    image_info_class=MMClassifierDatasetInfo,\n",
    "    normalization=False\n",
    ")\n",
    "mm_dataloader = DataLoader(mm_dataset, batch_size=6, shuffle=False)\n",
    "\n",
    "model_handler = ModelFilesHandler()"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CNN",
   "id": "25f415126fe8d2e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T16:47:08.185960Z",
     "start_time": "2024-12-18T16:46:54.410800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_name = r\"best_models\\CNN\\model_cnn_2024_12_14_13_20_07.pickle\"\n",
    "model, _, _, _ = model_handler.load_model(file_name=file_name)\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "current_predictions = []\n",
    "current_labels = []\n",
    "for batch_id, (images, mag1c, labels) in enumerate(dataloader):\n",
    "    input_image = torch.cat((images, mag1c), dim=1).to(device)\n",
    "    labels = labels.long().to(device)\n",
    "\n",
    "    outputs = model(input_image)\n",
    "    predictions = torch.argmax(outputs, dim=1)\n",
    "\n",
    "    current_predictions.append(predictions.cpu().detach())\n",
    "    current_labels.append(labels.cpu().detach())\n",
    "\n",
    "all_predictions = torch.cat(current_predictions)\n",
    "all_labels = torch.cat(current_labels)\n",
    "print(\"CNN finished.\")"
   ],
   "id": "1fd6f716f0b44ac8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN finished.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DETR",
   "id": "703b3e3e5f8d817e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T16:47:26.421061Z",
     "start_time": "2024-12-18T16:47:08.362546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_name = r\"best_models\\DETR\\model_detr_2024_12_15_11_35_17.pickle\"\n",
    "model, _, _, _ = model_handler.load_model(file_name=file_name)\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "current_predictions = []\n",
    "for batch_id, (images, mag1c, labels) in enumerate(dataloader):\n",
    "    input_image = torch.cat((images, mag1c), dim=1).to(device)\n",
    "    labels = labels.long().to(device)\n",
    "\n",
    "    outputs = model(input_image)\n",
    "    predictions = torch.argmax(outputs, dim=1)\n",
    "\n",
    "    current_predictions.append(predictions.cpu().detach())\n",
    "\n",
    "all_predictions = torch.add(all_predictions, torch.cat(current_predictions))\n",
    "print(\"DETR finished.\")"
   ],
   "id": "bcdcaaf932df56a1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\studia\\polsl_ssi_1\\MethaneDetection\\Thesis\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETR finished.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MethaneMapper",
   "id": "c316d988227aaab3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T16:51:29.612800Z",
     "start_time": "2024-12-18T16:47:26.475972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_name = r\"best_models\\MethaneMapper\\model_transformer_classifier_2024_12_12_12_51_44.pickle\"\n",
    "model, _, _, _ = model_handler.load_model(file_name=file_name)\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "current_predictions = []\n",
    "for batch_id, (images, mag1c, filtered_image, labels) in enumerate(mm_dataloader):\n",
    "    input_image = torch.cat((images, mag1c), dim=1).to(device)\n",
    "    filtered_image = filtered_image.to(device)\n",
    "    labels = labels.long().to(device)\n",
    "\n",
    "    outputs = model(input_image, filtered_image)\n",
    "    predictions = torch.argmax(outputs, dim=1)\n",
    "\n",
    "    current_predictions.append(predictions.cpu().detach())\n",
    "\n",
    "all_predictions = torch.add(all_predictions, torch.cat(current_predictions))\n",
    "\n",
    "print(\"Methane mapper finished.\")"
   ],
   "id": "682b41e41a5eb3e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Methane mapper finished.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ViT",
   "id": "b03b003bd987fb21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T16:52:16.963708Z",
     "start_time": "2024-12-18T16:51:29.726013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_name = r\"best_models\\VIT\\model_vit_2024_12_15_11_50_56.pickle\"\n",
    "model, _, _, _ = model_handler.load_model(file_name=file_name)\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "current_predictions = []\n",
    "for batch_id, (images, mag1c, labels) in enumerate(dataloader):\n",
    "    input_image = torch.cat((images, mag1c), dim=1).to(device)\n",
    "    labels = labels.long().to(device)\n",
    "\n",
    "    outputs = model(input_image)\n",
    "    predictions = torch.argmax(outputs, dim=1)\n",
    "\n",
    "    current_predictions.append(predictions.cpu().detach())\n",
    "\n",
    "all_predictions = torch.add(all_predictions, torch.cat(current_predictions))\n",
    "\n",
    "print(\"VIT finished.\")\n",
    "print(all_predictions)"
   ],
   "id": "dc50cc71e62c9eeb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIT finished.\n",
      "tensor([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4,\n",
      "        2, 4, 3, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 3, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 2, 4, 4, 4, 1, 4, 4, 2,\n",
      "        4, 4, 3, 1, 2, 4, 4, 3, 4, 3, 3, 4, 4, 4, 4, 4, 2, 2, 4, 4, 4, 2, 2, 4,\n",
      "        4, 2, 4, 3, 3, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 3, 3, 2, 4, 4, 4, 4, 4, 3,\n",
      "        4, 4, 3, 3, 3, 3, 4, 3, 2, 2, 4, 4, 3, 4, 3, 3, 1, 3, 4, 3, 3, 3, 3, 1,\n",
      "        4, 4, 1, 3, 3, 3])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prepare conclusions",
   "id": "c14afdedca22c7c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T16:52:16.973754Z",
     "start_time": "2024-12-18T16:52:16.966713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "from measures import ModelType\n",
    "from measures import MeasureToolFactory\n",
    "\n",
    "csv_path = r\"notebooks/classifier_committee_measures_old_mm.csv\"\n",
    "measurer = MeasureToolFactory.get_measure_tool(ModelType.TRANSFORMER)\n",
    "labels = all_labels[:]\n",
    "\n",
    "columns = [\n",
    "    'conclusion_type','tp', 'fp', 'fn', 'tn', 'precision', 'sensitivity',\n",
    "    'specificity', 'npv', 'fpr', 'accuracy', 'fscore', 'iou', 'mcc', 'auc', 'ci',\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(columns=columns)\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "def measure_and_save(min_detections):\n",
    "    pred = torch.Tensor([int(x >= min_detections) for x in all_predictions])\n",
    "    measures = measurer.compute_measures(pred, labels)\n",
    "    print(measures)\n",
    "\n",
    "    conclusion_info = f\"at least {min_detections} detection{\"s\" if min_detections > 1 else \"\"}\"\n",
    "    measure_info = pd.DataFrame.from_dict({\"conculsion_type\":[conclusion_info]})\n",
    "\n",
    "    row = pd.concat([measure_info, measures], axis=1)\n",
    "    row.to_csv(csv_path, mode='a', index=False, header=False)"
   ],
   "id": "64f25772d5a55f9c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Conclusion - at least 1 detection",
   "id": "aa528cda6b0582fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T16:52:17.040973Z",
     "start_time": "2024-12-18T16:52:17.031961Z"
    }
   },
   "cell_type": "code",
   "source": "measure_and_save(min_detections=1)",
   "id": "98ffac523c611083",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        TP        FP        FN        TN  Precision  Sensitivity  Specificity  \\\n",
      "0  0.48538  0.049708  0.002924  0.461988   0.907102      0.99401     0.902855   \n",
      "\n",
      "        NPV       FPR  Accuracy   F-Score       IoU       MCC       AUC  \\\n",
      "0  0.993709  0.097143  0.947367  0.948569  0.902174  0.898836  0.948435   \n",
      "\n",
      "         CI  \n",
      "0  0.052939  \n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Conclusion - at least 2 detections",
   "id": "8f39abb4c2645042"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T16:52:17.111237Z",
     "start_time": "2024-12-18T16:52:17.102102Z"
    }
   },
   "cell_type": "code",
   "source": "measure_and_save(min_detections=2)\n",
   "id": "f2f54cd26e3f5c14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        TP   FP        FN        TN  Precision  Sensitivity  Specificity  \\\n",
      "0  0.47076  0.0  0.017544  0.511696   0.999998      0.96407     0.999998   \n",
      "\n",
      "        NPV  FPR  Accuracy   F-Score       IoU       MCC       AUC        CI  \n",
      "0  0.966849  0.0  0.982455  0.981705  0.964072  0.965456  0.982036  0.052979  \n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Conclusion - at least 3 detections",
   "id": "94765c1081539137"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T16:52:17.168208Z",
     "start_time": "2024-12-18T16:52:17.159188Z"
    }
   },
   "cell_type": "code",
   "source": "measure_and_save(min_detections=3)\n",
   "id": "3444c903677355e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         TP   FP       FN        TN  Precision  Sensitivity  Specificity  \\\n",
      "0  0.429825  0.0  0.05848  0.511696   0.999998     0.880238     0.999998   \n",
      "\n",
      "        NPV  FPR  Accuracy   F-Score      IoU       MCC      AUC        CI  \n",
      "0  0.897434  0.0   0.94152  0.936303  0.88024  0.888793  0.94012  0.052545  \n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Conclusion - at least 4 detections",
   "id": "2c49b7ea0f5ccc95"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T16:52:17.224694Z",
     "start_time": "2024-12-18T16:52:17.216850Z"
    }
   },
   "cell_type": "code",
   "source": "measure_and_save(min_detections=4)",
   "id": "9da69dc01bbff017",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         TP   FP        FN        TN  Precision  Sensitivity  Specificity  \\\n",
      "0  0.324561  0.0  0.163743  0.511696   0.999997     0.664669     0.999998   \n",
      "\n",
      "        NPV  FPR  Accuracy   F-Score       IoU       MCC       AUC        CI  \n",
      "0  0.757575  0.0  0.836256  0.798559  0.664671  0.709601  0.832335  0.049696  \n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
