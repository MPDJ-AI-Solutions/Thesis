{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Eniviroment setup",
   "id": "bd2788c92659ad2f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-14T11:02:56.827084Z",
     "start_time": "2024-12-14T11:02:52.374011Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import vit_b_16\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from dataset.dataset_info import ClassifierDatasetInfo, DatasetInfo\n",
    "from dataset.dataset_type import DatasetType\n",
    "from dataset.STARCOP_dataset import STARCOPDataset\n",
    "\n",
    "from models.Tools.FilesHandler.model_files_handler import ModelFilesHandler\n",
    "from models.Tools.Measures.measure_tool_factory import MeasureToolFactory\n",
    "from models.Tools.Measures.model_type import ModelType\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from typing import Type\n",
    "\n",
    "os.chdir(r\"C:\\Users\\mpilc\\Desktop\\Studia\\Thesis\\Repozytoria\\Thesis\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setup datasets\n",
    "STARCOPDataset is custom class that derives torch.utils.data.Dataset class. It's defined in dataset module."
   ],
   "id": "f1080e782a0be239"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T11:02:56.840518Z",
     "start_time": "2024-12-14T11:02:56.835855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def setup_dataloaders(\n",
    "        data_path: str = r\"data\",\n",
    "        batch_size: int = 32,\n",
    "        train_type = DatasetType.EASY_TRAIN,\n",
    "        image_info_class: Type[DatasetInfo] = ClassifierDatasetInfo,\n",
    "        crop_size: int = 1\n",
    "):\n",
    "    train_dataset = STARCOPDataset(\n",
    "        data_path=data_path,\n",
    "        data_type=train_type,\n",
    "        image_info_class=image_info_class,\n",
    "        crop_size=crop_size\n",
    "    )\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    test_dataset = STARCOPDataset(\n",
    "        data_path=data_path,\n",
    "        data_type=DatasetType.TEST,\n",
    "        image_info_class=image_info_class,\n",
    "        crop_size=crop_size\n",
    "    )\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_dataloader, test_dataloader"
   ],
   "id": "633a22ebce25443b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setup models\n",
    "\n",
    "### Model class"
   ],
   "id": "55aade7bf5249f30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T11:02:57.029941Z",
     "start_time": "2024-12-14T11:02:57.025134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomViT(nn.Module):\n",
    "    def __init__(self, num_channels=9, num_classes=2):\n",
    "        super(CustomViT, self).__init__()\n",
    "        # Load pre-trained ViT model\n",
    "        self.vit = vit_b_16(weights=None)  # Use pretrained weights if desired\n",
    "\n",
    "        # Modify the input embedding layer to accept `num_channels`\n",
    "        self.vit.conv_proj = nn.Conv2d(num_channels, self.vit.conv_proj.out_channels,\n",
    "                                       kernel_size=self.vit.conv_proj.kernel_size,\n",
    "                                       stride=self.vit.conv_proj.stride,\n",
    "                                       padding=self.vit.conv_proj.padding,\n",
    "                                       bias=(self.vit.conv_proj.bias is not None))\n",
    "\n",
    "        # Modify the classifier head for binary classification\n",
    "        self.vit.heads = nn.Sequential(\n",
    "            nn.Linear(self.vit.heads.head.in_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.resize = nn.Upsample(size=(224, 224), mode='bilinear', align_corners=False)\n",
    "        self.normalize = transforms.Normalize(mean=[0.5] * num_channels, std=[0.5] * num_channels)        \n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        x = self.resize(x)\n",
    "        x = self.normalize(x)\n",
    "        print(x.shape)\n",
    "        return self.vit(x)"
   ],
   "id": "8f28a27507f2ad99",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prepare models ",
   "id": "35324cba37646987"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T11:02:57.039691Z",
     "start_time": "2024-12-14T11:02:57.035116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def setup_model(model: nn.Module, lr: float, device: str):\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()  # Binary classification\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    return model, criterion, optimizer"
   ],
   "id": "4fbb9f2106cd78f2",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare training function",
   "id": "ef59708b5382f94"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b1f84871b7e700c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T11:02:57.049442Z",
     "start_time": "2024-12-14T11:02:57.045845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_progress_bar(percentage, loss):\n",
    "    bar_length = 50  # Length of the progress bar\n",
    "    filled_length = int(bar_length * percentage // 100)\n",
    "    bar = '=' * filled_length + '-' * (bar_length - filled_length)\n",
    "    sys.stdout.write(f\"\\r[{bar}] {percentage:.2f}% [Loss: {loss:.6f}]\")\n",
    "    sys.stdout.flush()"
   ],
   "id": "26251c87110288d6",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "da24e4a1d5e46fb3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T11:02:57.059730Z",
     "start_time": "2024-12-14T11:02:57.055116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(criterion, device, epochs, model, optimizer, dataloader, model_handler, log_batches: bool = False):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):  \n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        running_loss = 0.0\n",
    "        for batch_id, (images, mag1c, labels) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            input_image = torch.cat((images, mag1c), dim=1).to(device)\n",
    "            labels = labels.long().to(device)\n",
    "\n",
    "            outputs = model(input_image)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if log_batches and (batch_id + 1) % 10 == 0:\n",
    "                print_progress_bar(batch_id / len(dataloader) * 100, running_loss / (batch_id + 1))\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(dataloader)}\")\n",
    "        model_handler.save_raw_model(model)"
   ],
   "id": "b4c4eb62cccb104c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare evaluate function",
   "id": "ead9dd1c2d9c4483"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T11:02:57.070405Z",
     "start_time": "2024-12-14T11:02:57.066288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate(criterion, device, model, dataloader, measurer):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_id, (images, mag1c, labels) in enumerate(dataloader):\n",
    "        input_image = torch.cat((images, mag1c), dim=1).to(device)\n",
    "        labels = labels.long().to(device)\n",
    "\n",
    "        outputs = model(input_image)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        all_predictions.append(predictions.cpu().detach())\n",
    "        all_labels.append(labels.cpu().detach())\n",
    "\n",
    "    measures = measurer.compute_measures(torch.cat(all_predictions), torch.cat(all_labels))\n",
    "    print(f\"Validation loss: {running_loss / len(dataloader)}.\\nMeasures:\\n{measures}\")\n",
    "    return measures"
   ],
   "id": "deed82ce61ddca3f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train model ",
   "id": "5a5f24876565680a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T11:05:29.413907Z",
     "start_time": "2024-12-14T11:02:57.076549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 15\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "lr = 1e-4\n",
    "\n",
    "# Override for file handler\n",
    "from models.Transformer.VIT.model import CustomViT\n",
    "\n",
    "train_dataloader, test_dataloader = setup_dataloaders(train_type=DatasetType.TRAIN)\n",
    "model = CustomViT()\n",
    "model, criterion, optimizer = setup_model(model, lr, device)\n",
    "model_handler = ModelFilesHandler()\n",
    "measurer = MeasureToolFactory.get_measure_tool(ModelType.TRANSFORMER)\n",
    "\n",
    "\n",
    "train(criterion, device, epochs, model, optimizer, train_dataloader, model_handler, log_batches=True)\n",
    "measures = evaluate(criterion, device, model, test_dataloader, measurer)"
   ],
   "id": "72d2ee60759244d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mpilc\\Desktop\\Studia\\Thesis\\Repozytoria\\Thesis\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:5560: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========================-------------------------] 50.00% [Loss: 0.760143]Epoch 1, Loss: 0.6893462008900113\n",
      "Validation loss: 0.5071701407432556.\n",
      "Measures:\n",
      "         TP        FP        FN        TN  Precision  Sensitivity  \\\n",
      "0  0.249267  0.014663  0.237537  0.498534   0.944441     0.512047   \n",
      "\n",
      "   Specificity      NPV       FPR  Accuracy  F-Score       IoU       MCC  \\\n",
      "0     0.971427  0.67729  0.028571    0.7478  0.66406  0.497076  0.548263   \n",
      "\n",
      "        AUC        CI  \n",
      "0  0.741738  0.046851  \n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Save model",
   "id": "e519706b2f962064"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T11:05:29.693015Z",
     "start_time": "2024-12-14T11:05:29.445544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_handler.save_model(\n",
    "    model=model,\n",
    "    metrics = measures,\n",
    "    model_type=ModelType.TRANSFORMER_CLASSIFIER,\n",
    "    epoch=epochs,\n",
    ")"
   ],
   "id": "d1aae91ca9193b16",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trained_models\\\\model_transformer_classifier_2024_12_14_12_05_29.pickle'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
